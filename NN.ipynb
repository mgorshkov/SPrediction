{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPredictionDataset(Dataset):\n",
    "    \"\"\"S Prediction dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        dtype = {'Point-ID': np.int32, 'Hole-ID': str, 'Sample': str, 'From': np.float64, 'To': np.float64, \n",
    "         'M': np.float64, 'Au': np.float64, 'Ag': np.float64, 'X': np.float64, 'Y': np.float64, 'Z': np.float64, \n",
    "         'Block': str, 'Date': str, 'S': np.float64, 'Fe': np.float64, 'Cu': np.float64, \n",
    "         'Zn': np.float64, 'As': np.float64, 'Cd': np.float64, 'Sb': np.float64, 'Pb': np.float64, 'Bi': np.float64, \n",
    "         'Au_eq': np.float64, 'Pb_eq': np.float64, 'Au_Cut': np.float64, 'Ag_Cut': np.float64, 'Pb_Cut': np.float64, \n",
    "         'Zn_Cut': np.float64, 'Cu_Cut': np.float64, 'As_Cut': np.float64, 'Sb_Cut': np.float64, \n",
    "         'RT_2021': str, 'Cd_Cut': np.float64, 'Bi_Cut': np.float64, 'Code': str, \n",
    "        'RT_2021_Бедные': str}\n",
    "        df = pd.read_csv(csv_file, sep=';', header='infer', na_values='na', \n",
    "                     keep_default_na=True, na_filter=True, verbose=False, decimal=',', dtype=dtype,\n",
    "                     usecols=['Au', 'Ag', 'S', 'Fe', 'Cu', 'Zn', 'As', 'Cd', 'Sb', 'Pb', 'Bi'])\n",
    "        \n",
    "        df_partial = df[['Ag', 'S', 'Fe', 'Cu', 'Sb', 'Pb', 'Bi']]\n",
    "        #print ('df_partial=', df_partial)\n",
    "        df_notnull = df_partial.notnull()\n",
    "        #print ('df_notnull=', df_notnull)\n",
    "        rows = df_notnull.all(1)\n",
    "        #print ('rows=', rows)\n",
    "        self.df = df[rows]\n",
    "        #print ('self.df=', self.df)\n",
    "\n",
    "        self.target = 'S'\n",
    "\n",
    "        # Save target and predictors\n",
    "        self.X = self.df.drop(self.target, axis=1)\n",
    "        #print ('self.X=', self.X)\n",
    "        self.y = self.df[self.target]\n",
    "        #print ('self.y=', self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X.iloc[idx].values, self.y.iloc[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, sizes, dropout=[], bn=False, activation_fn=nn.Tanh(), flatten=False, \n",
    "                 last_fn=None, first_fn=None, device='cpu'):\n",
    "        super(FullyConnected, self).__init__()\n",
    "        layers = []\n",
    "        self.flatten = flatten\n",
    "        if first_fn is not None:\n",
    "            layers.append(first_fn)\n",
    "        for i in range(len(sizes) - 2):\n",
    "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
    "            layers.append(activation_fn)\n",
    "            if bn:\n",
    "                layers.append(nn.BatchNorm1d(sizes[i+1]))\n",
    "            if dropout:\n",
    "                layers.append(nn.Dropout(dropout[i]))\n",
    "        else: \n",
    "            layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
    "        if last_fn is not None:\n",
    "            layers.append(last_fn)\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        if self.flatten:\n",
    "            x = x.view(x.shape[0], -1)\n",
    "        if y is not None:\n",
    "            x = torch.cat([x, y], dim=1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dims, dropout=[], bn=False, activation_fn=nn.ReLU(), last_fn=nn.ReLU(), lr=0.001, lr_decay=0.0001, weight_decay=0.01):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = FullyConnected(dims, dropout=dropout, bn=bn, activation_fn=activation_fn, last_fn=last_fn, flatten=False, device=device)\n",
    "        self.optimizer = optim.Adagrad(self.parameters(), lr=lr, lr_decay=lr_decay, \n",
    "                                       weight_decay=weight_decay, initial_accumulator_value=0, eps=1e-10)\n",
    "        self.loss = torch.nn.MSELoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mode, train_loader):\n",
    "    print ('Training on device {}'.format(device))\n",
    "    \n",
    "    epochs = 100\n",
    "    train_size = len(train_loader)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (X_train, y_train) in enumerate(train_loader):\n",
    "            #print (\"X_train=\", X_train)\n",
    "            model.optimizer.zero_grad()\n",
    "            X_train_tensor = X_train.float().to(device)\n",
    "            y_train_tensor = y_train.float().to(device)\n",
    "            y_pred = model(X_train_tensor)\n",
    "            y_pred = y_pred.view(-1)\n",
    "            #print ('y_pred.shape',y_pred.shape)\n",
    "            #print ('y_train_tensor.shape',y_train_tensor.shape)\n",
    "            loss = model.loss(y_pred, y_train_tensor)\n",
    "            loss.backward()\n",
    "\n",
    "            model.optimizer.step()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "                    epoch, batch_idx, train_size, 100. * batch_idx / train_size)\n",
    "                losses = '{:.4f}'.format(loss.item())\n",
    "                print(line + losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    dataiter = iter(test_loader)\n",
    "    X_test, y_test = dataiter.next()\n",
    "\n",
    "    X_test_tensor = X_test.float().to(device)\n",
    "    y_test_tensor = y_test.float().to(device)\n",
    "        \n",
    "    y_pred = model(X_test_tensor)\n",
    "    y_pred = y_pred.view(-1)\n",
    "        \n",
    "    loss = model.loss(y_pred, y_test_tensor).item()\n",
    "        \n",
    "    print (\"Test loss={:.4f}\".format(loss))\n",
    "    print (\"y_pred=\", y_pred)\n",
    "    print (\"y_test=\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (fc): FullyConnected(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=1000, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.001, inplace=False)\n",
      "      (4): Linear(in_features=1000, out_features=500, bias=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): Dropout(p=0.01, inplace=False)\n",
      "      (8): Linear(in_features=500, out_features=250, bias=True)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): Dropout(p=0.01, inplace=False)\n",
      "      (12): Linear(in_features=250, out_features=1, bias=True)\n",
      "      (13): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (loss): MSELoss()\n",
      ")\n",
      "train_size= 82701\n",
      "test_size= 20676\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = SPredictionDataset('DH_ASSAY_General_2021.csv')\n",
    "\n",
    "#print ('dataset.X.shape[1]=', dataset.X.shape[1])\n",
    "# Define model\n",
    "layers = dataset.X.shape[1], 1000, 500, 250, 1\n",
    "model = Model(layers, dropout=[0.001, 0.01, 0.01], bn=True, activation_fn=nn.ReLU(inplace=True),\n",
    "              last_fn=nn.ReLU(inplace=True), \n",
    "              lr=.001, \n",
    "              weight_decay=0.0001)\n",
    "print (model)\n",
    "\n",
    "# Split into training and test\n",
    "train_size = int(0.8 * len(dataset))\n",
    "print ('train_size=', train_size)\n",
    "test_size = len(dataset) - train_size\n",
    "print ('test_size=', test_size)\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size=200, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda:0\n",
      "Train Epoch: 0 [0/414 (0%)]\tLosses 8.2205\n",
      "Train Epoch: 0 [100/414 (24%)]\tLosses 0.7327\n",
      "Train Epoch: 0 [200/414 (48%)]\tLosses 1.5559\n",
      "Train Epoch: 0 [300/414 (72%)]\tLosses 14.6150\n",
      "Train Epoch: 0 [400/414 (97%)]\tLosses 16.7970\n",
      "Train Epoch: 1 [0/414 (0%)]\tLosses 2.6718\n",
      "Train Epoch: 1 [100/414 (24%)]\tLosses 1.3571\n",
      "Train Epoch: 1 [200/414 (48%)]\tLosses 1.3325\n",
      "Train Epoch: 1 [300/414 (72%)]\tLosses 1.6373\n",
      "Train Epoch: 1 [400/414 (97%)]\tLosses 0.7128\n",
      "Train Epoch: 2 [0/414 (0%)]\tLosses 0.7749\n",
      "Train Epoch: 2 [100/414 (24%)]\tLosses 0.7392\n",
      "Train Epoch: 2 [200/414 (48%)]\tLosses 1.1895\n",
      "Train Epoch: 2 [300/414 (72%)]\tLosses 0.6846\n",
      "Train Epoch: 2 [400/414 (97%)]\tLosses 0.7686\n",
      "Train Epoch: 3 [0/414 (0%)]\tLosses 0.9260\n",
      "Train Epoch: 3 [100/414 (24%)]\tLosses 0.7797\n",
      "Train Epoch: 3 [200/414 (48%)]\tLosses 1.2093\n",
      "Train Epoch: 3 [300/414 (72%)]\tLosses 0.9574\n",
      "Train Epoch: 3 [400/414 (97%)]\tLosses 0.8229\n",
      "Train Epoch: 4 [0/414 (0%)]\tLosses 6.8793\n",
      "Train Epoch: 4 [100/414 (24%)]\tLosses 0.9683\n",
      "Train Epoch: 4 [200/414 (48%)]\tLosses 1.0029\n",
      "Train Epoch: 4 [300/414 (72%)]\tLosses 0.7956\n",
      "Train Epoch: 4 [400/414 (97%)]\tLosses 3.3659\n",
      "Train Epoch: 5 [0/414 (0%)]\tLosses 0.4835\n",
      "Train Epoch: 5 [100/414 (24%)]\tLosses 1.1137\n",
      "Train Epoch: 5 [200/414 (48%)]\tLosses 9.7052\n",
      "Train Epoch: 5 [300/414 (72%)]\tLosses 1.3271\n",
      "Train Epoch: 5 [400/414 (97%)]\tLosses 1.0965\n",
      "Train Epoch: 6 [0/414 (0%)]\tLosses 0.7795\n",
      "Train Epoch: 6 [100/414 (24%)]\tLosses 2.1760\n",
      "Train Epoch: 6 [200/414 (48%)]\tLosses 3.6794\n",
      "Train Epoch: 6 [300/414 (72%)]\tLosses 0.8358\n",
      "Train Epoch: 6 [400/414 (97%)]\tLosses 1.1798\n",
      "Train Epoch: 7 [0/414 (0%)]\tLosses 11.8795\n",
      "Train Epoch: 7 [100/414 (24%)]\tLosses 1.1546\n",
      "Train Epoch: 7 [200/414 (48%)]\tLosses 1.2313\n",
      "Train Epoch: 7 [300/414 (72%)]\tLosses 1.6483\n",
      "Train Epoch: 7 [400/414 (97%)]\tLosses 2.4411\n",
      "Train Epoch: 8 [0/414 (0%)]\tLosses 1.4006\n",
      "Train Epoch: 8 [100/414 (24%)]\tLosses 0.5667\n",
      "Train Epoch: 8 [200/414 (48%)]\tLosses 0.7369\n",
      "Train Epoch: 8 [300/414 (72%)]\tLosses 4.3976\n",
      "Train Epoch: 8 [400/414 (97%)]\tLosses 1.0923\n",
      "Train Epoch: 9 [0/414 (0%)]\tLosses 0.6255\n",
      "Train Epoch: 9 [100/414 (24%)]\tLosses 0.5895\n",
      "Train Epoch: 9 [200/414 (48%)]\tLosses 1.1831\n",
      "Train Epoch: 9 [300/414 (72%)]\tLosses 0.7578\n",
      "Train Epoch: 9 [400/414 (97%)]\tLosses 0.8808\n",
      "Train Epoch: 10 [0/414 (0%)]\tLosses 0.8683\n",
      "Train Epoch: 10 [100/414 (24%)]\tLosses 0.6731\n",
      "Train Epoch: 10 [200/414 (48%)]\tLosses 0.8116\n",
      "Train Epoch: 10 [300/414 (72%)]\tLosses 0.5561\n",
      "Train Epoch: 10 [400/414 (97%)]\tLosses 0.8465\n",
      "Train Epoch: 11 [0/414 (0%)]\tLosses 0.6575\n",
      "Train Epoch: 11 [100/414 (24%)]\tLosses 1.7851\n",
      "Train Epoch: 11 [200/414 (48%)]\tLosses 0.7460\n",
      "Train Epoch: 11 [300/414 (72%)]\tLosses 0.7851\n",
      "Train Epoch: 11 [400/414 (97%)]\tLosses 1.2448\n",
      "Train Epoch: 12 [0/414 (0%)]\tLosses 0.5795\n",
      "Train Epoch: 12 [100/414 (24%)]\tLosses 0.6349\n",
      "Train Epoch: 12 [200/414 (48%)]\tLosses 0.7783\n",
      "Train Epoch: 12 [300/414 (72%)]\tLosses 1.2098\n",
      "Train Epoch: 12 [400/414 (97%)]\tLosses 1.1491\n",
      "Train Epoch: 13 [0/414 (0%)]\tLosses 0.8225\n",
      "Train Epoch: 13 [100/414 (24%)]\tLosses 2.0104\n",
      "Train Epoch: 13 [200/414 (48%)]\tLosses 0.8220\n",
      "Train Epoch: 13 [300/414 (72%)]\tLosses 0.8563\n",
      "Train Epoch: 13 [400/414 (97%)]\tLosses 1.4163\n",
      "Train Epoch: 14 [0/414 (0%)]\tLosses 0.6643\n",
      "Train Epoch: 14 [100/414 (24%)]\tLosses 0.7937\n",
      "Train Epoch: 14 [200/414 (48%)]\tLosses 0.5224\n",
      "Train Epoch: 14 [300/414 (72%)]\tLosses 2.5392\n",
      "Train Epoch: 14 [400/414 (97%)]\tLosses 2.1842\n",
      "Train Epoch: 15 [0/414 (0%)]\tLosses 0.6003\n",
      "Train Epoch: 15 [100/414 (24%)]\tLosses 0.6866\n",
      "Train Epoch: 15 [200/414 (48%)]\tLosses 0.6842\n",
      "Train Epoch: 15 [300/414 (72%)]\tLosses 3.2809\n",
      "Train Epoch: 15 [400/414 (97%)]\tLosses 0.7428\n",
      "Train Epoch: 16 [0/414 (0%)]\tLosses 1.8130\n",
      "Train Epoch: 16 [100/414 (24%)]\tLosses 0.6470\n",
      "Train Epoch: 16 [200/414 (48%)]\tLosses 0.5884\n",
      "Train Epoch: 16 [300/414 (72%)]\tLosses 0.5443\n",
      "Train Epoch: 16 [400/414 (97%)]\tLosses 0.8551\n",
      "Train Epoch: 17 [0/414 (0%)]\tLosses 0.7061\n",
      "Train Epoch: 17 [100/414 (24%)]\tLosses 0.5578\n",
      "Train Epoch: 17 [200/414 (48%)]\tLosses 1.7588\n",
      "Train Epoch: 17 [300/414 (72%)]\tLosses 1.0247\n",
      "Train Epoch: 17 [400/414 (97%)]\tLosses 0.7908\n",
      "Train Epoch: 18 [0/414 (0%)]\tLosses 0.6332\n",
      "Train Epoch: 18 [100/414 (24%)]\tLosses 2.7911\n",
      "Train Epoch: 18 [200/414 (48%)]\tLosses 0.6559\n",
      "Train Epoch: 18 [300/414 (72%)]\tLosses 1.0645\n",
      "Train Epoch: 18 [400/414 (97%)]\tLosses 1.7326\n",
      "Train Epoch: 19 [0/414 (0%)]\tLosses 0.6056\n",
      "Train Epoch: 19 [100/414 (24%)]\tLosses 2.2505\n",
      "Train Epoch: 19 [200/414 (48%)]\tLosses 0.8129\n",
      "Train Epoch: 19 [300/414 (72%)]\tLosses 1.0692\n",
      "Train Epoch: 19 [400/414 (97%)]\tLosses 1.1797\n",
      "Train Epoch: 20 [0/414 (0%)]\tLosses 0.7596\n",
      "Train Epoch: 20 [100/414 (24%)]\tLosses 1.0096\n",
      "Train Epoch: 20 [200/414 (48%)]\tLosses 1.1848\n",
      "Train Epoch: 20 [300/414 (72%)]\tLosses 1.9330\n",
      "Train Epoch: 20 [400/414 (97%)]\tLosses 0.6045\n",
      "Train Epoch: 21 [0/414 (0%)]\tLosses 0.8981\n",
      "Train Epoch: 21 [100/414 (24%)]\tLosses 0.9535\n",
      "Train Epoch: 21 [200/414 (48%)]\tLosses 1.4508\n",
      "Train Epoch: 21 [300/414 (72%)]\tLosses 0.8583\n",
      "Train Epoch: 21 [400/414 (97%)]\tLosses 0.9761\n",
      "Train Epoch: 22 [0/414 (0%)]\tLosses 0.9578\n",
      "Train Epoch: 22 [100/414 (24%)]\tLosses 0.3301\n",
      "Train Epoch: 22 [200/414 (48%)]\tLosses 9.3270\n",
      "Train Epoch: 22 [300/414 (72%)]\tLosses 1.0490\n",
      "Train Epoch: 22 [400/414 (97%)]\tLosses 0.6762\n",
      "Train Epoch: 23 [0/414 (0%)]\tLosses 0.8975\n",
      "Train Epoch: 23 [100/414 (24%)]\tLosses 0.8496\n",
      "Train Epoch: 23 [200/414 (48%)]\tLosses 1.3114\n",
      "Train Epoch: 23 [300/414 (72%)]\tLosses 1.0996\n",
      "Train Epoch: 23 [400/414 (97%)]\tLosses 1.3911\n",
      "Train Epoch: 24 [0/414 (0%)]\tLosses 0.4853\n",
      "Train Epoch: 24 [100/414 (24%)]\tLosses 0.5246\n",
      "Train Epoch: 24 [200/414 (48%)]\tLosses 0.5826\n",
      "Train Epoch: 24 [300/414 (72%)]\tLosses 1.7341\n",
      "Train Epoch: 24 [400/414 (97%)]\tLosses 0.9811\n",
      "Train Epoch: 25 [0/414 (0%)]\tLosses 0.5858\n",
      "Train Epoch: 25 [100/414 (24%)]\tLosses 0.7934\n",
      "Train Epoch: 25 [200/414 (48%)]\tLosses 0.6873\n",
      "Train Epoch: 25 [300/414 (72%)]\tLosses 1.5024\n",
      "Train Epoch: 25 [400/414 (97%)]\tLosses 8.7298\n",
      "Train Epoch: 26 [0/414 (0%)]\tLosses 0.8023\n",
      "Train Epoch: 26 [100/414 (24%)]\tLosses 1.0651\n",
      "Train Epoch: 26 [200/414 (48%)]\tLosses 0.4129\n",
      "Train Epoch: 26 [300/414 (72%)]\tLosses 2.1919\n",
      "Train Epoch: 26 [400/414 (97%)]\tLosses 1.7097\n",
      "Train Epoch: 27 [0/414 (0%)]\tLosses 0.6704\n",
      "Train Epoch: 27 [100/414 (24%)]\tLosses 0.7268\n",
      "Train Epoch: 27 [200/414 (48%)]\tLosses 1.2211\n",
      "Train Epoch: 27 [300/414 (72%)]\tLosses 0.8727\n",
      "Train Epoch: 27 [400/414 (97%)]\tLosses 1.2418\n",
      "Train Epoch: 28 [0/414 (0%)]\tLosses 0.5970\n",
      "Train Epoch: 28 [100/414 (24%)]\tLosses 0.6325\n",
      "Train Epoch: 28 [200/414 (48%)]\tLosses 1.5055\n",
      "Train Epoch: 28 [300/414 (72%)]\tLosses 0.7475\n",
      "Train Epoch: 28 [400/414 (97%)]\tLosses 0.6356\n",
      "Train Epoch: 29 [0/414 (0%)]\tLosses 1.0714\n",
      "Train Epoch: 29 [100/414 (24%)]\tLosses 0.6067\n",
      "Train Epoch: 29 [200/414 (48%)]\tLosses 0.6752\n",
      "Train Epoch: 29 [300/414 (72%)]\tLosses 0.5689\n",
      "Train Epoch: 29 [400/414 (97%)]\tLosses 1.0034\n",
      "Train Epoch: 30 [0/414 (0%)]\tLosses 0.6328\n",
      "Train Epoch: 30 [100/414 (24%)]\tLosses 0.7208\n",
      "Train Epoch: 30 [200/414 (48%)]\tLosses 1.4503\n",
      "Train Epoch: 30 [300/414 (72%)]\tLosses 1.7331\n",
      "Train Epoch: 30 [400/414 (97%)]\tLosses 0.4916\n",
      "Train Epoch: 31 [0/414 (0%)]\tLosses 0.9959\n",
      "Train Epoch: 31 [100/414 (24%)]\tLosses 0.8783\n",
      "Train Epoch: 31 [200/414 (48%)]\tLosses 0.7716\n",
      "Train Epoch: 31 [300/414 (72%)]\tLosses 0.7124\n",
      "Train Epoch: 31 [400/414 (97%)]\tLosses 0.8479\n",
      "Train Epoch: 32 [0/414 (0%)]\tLosses 1.3355\n",
      "Train Epoch: 32 [100/414 (24%)]\tLosses 1.4257\n",
      "Train Epoch: 32 [200/414 (48%)]\tLosses 0.4277\n",
      "Train Epoch: 32 [300/414 (72%)]\tLosses 0.8234\n",
      "Train Epoch: 32 [400/414 (97%)]\tLosses 1.4767\n",
      "Train Epoch: 33 [0/414 (0%)]\tLosses 0.7477\n",
      "Train Epoch: 33 [100/414 (24%)]\tLosses 0.6311\n",
      "Train Epoch: 33 [200/414 (48%)]\tLosses 0.8368\n",
      "Train Epoch: 33 [300/414 (72%)]\tLosses 0.5895\n",
      "Train Epoch: 33 [400/414 (97%)]\tLosses 12.0557\n",
      "Train Epoch: 34 [0/414 (0%)]\tLosses 1.1136\n",
      "Train Epoch: 34 [100/414 (24%)]\tLosses 4.9099\n",
      "Train Epoch: 34 [200/414 (48%)]\tLosses 0.6516\n",
      "Train Epoch: 34 [300/414 (72%)]\tLosses 0.7769\n",
      "Train Epoch: 34 [400/414 (97%)]\tLosses 0.8634\n",
      "Train Epoch: 35 [0/414 (0%)]\tLosses 1.0681\n",
      "Train Epoch: 35 [100/414 (24%)]\tLosses 0.4545\n",
      "Train Epoch: 35 [200/414 (48%)]\tLosses 0.9124\n",
      "Train Epoch: 35 [300/414 (72%)]\tLosses 1.1342\n",
      "Train Epoch: 35 [400/414 (97%)]\tLosses 1.0522\n",
      "Train Epoch: 36 [0/414 (0%)]\tLosses 0.6385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 36 [100/414 (24%)]\tLosses 1.7879\n",
      "Train Epoch: 36 [200/414 (48%)]\tLosses 1.4845\n",
      "Train Epoch: 36 [300/414 (72%)]\tLosses 1.5331\n",
      "Train Epoch: 36 [400/414 (97%)]\tLosses 3.4575\n",
      "Train Epoch: 37 [0/414 (0%)]\tLosses 0.6640\n",
      "Train Epoch: 37 [100/414 (24%)]\tLosses 0.5358\n",
      "Train Epoch: 37 [200/414 (48%)]\tLosses 0.5935\n",
      "Train Epoch: 37 [300/414 (72%)]\tLosses 0.7249\n",
      "Train Epoch: 37 [400/414 (97%)]\tLosses 0.6962\n",
      "Train Epoch: 38 [0/414 (0%)]\tLosses 4.7442\n",
      "Train Epoch: 38 [100/414 (24%)]\tLosses 0.8398\n",
      "Train Epoch: 38 [200/414 (48%)]\tLosses 0.5186\n",
      "Train Epoch: 38 [300/414 (72%)]\tLosses 0.7789\n",
      "Train Epoch: 38 [400/414 (97%)]\tLosses 0.6595\n",
      "Train Epoch: 39 [0/414 (0%)]\tLosses 0.5220\n",
      "Train Epoch: 39 [100/414 (24%)]\tLosses 0.8637\n",
      "Train Epoch: 39 [200/414 (48%)]\tLosses 0.7581\n",
      "Train Epoch: 39 [300/414 (72%)]\tLosses 0.5973\n",
      "Train Epoch: 39 [400/414 (97%)]\tLosses 0.7005\n",
      "Train Epoch: 40 [0/414 (0%)]\tLosses 1.8514\n",
      "Train Epoch: 40 [100/414 (24%)]\tLosses 0.6345\n",
      "Train Epoch: 40 [200/414 (48%)]\tLosses 0.6885\n",
      "Train Epoch: 40 [300/414 (72%)]\tLosses 0.6676\n",
      "Train Epoch: 40 [400/414 (97%)]\tLosses 0.6027\n",
      "Train Epoch: 41 [0/414 (0%)]\tLosses 1.5291\n",
      "Train Epoch: 41 [100/414 (24%)]\tLosses 0.5059\n",
      "Train Epoch: 41 [200/414 (48%)]\tLosses 0.9561\n",
      "Train Epoch: 41 [300/414 (72%)]\tLosses 0.6504\n",
      "Train Epoch: 41 [400/414 (97%)]\tLosses 1.0517\n",
      "Train Epoch: 42 [0/414 (0%)]\tLosses 1.4735\n",
      "Train Epoch: 42 [100/414 (24%)]\tLosses 0.6476\n",
      "Train Epoch: 42 [200/414 (48%)]\tLosses 1.0683\n",
      "Train Epoch: 42 [300/414 (72%)]\tLosses 0.5164\n",
      "Train Epoch: 42 [400/414 (97%)]\tLosses 0.8508\n",
      "Train Epoch: 43 [0/414 (0%)]\tLosses 0.8742\n",
      "Train Epoch: 43 [100/414 (24%)]\tLosses 0.9428\n",
      "Train Epoch: 43 [200/414 (48%)]\tLosses 0.6374\n",
      "Train Epoch: 43 [300/414 (72%)]\tLosses 0.9124\n",
      "Train Epoch: 43 [400/414 (97%)]\tLosses 0.5923\n",
      "Train Epoch: 44 [0/414 (0%)]\tLosses 1.6627\n",
      "Train Epoch: 44 [100/414 (24%)]\tLosses 0.9323\n",
      "Train Epoch: 44 [200/414 (48%)]\tLosses 1.4194\n",
      "Train Epoch: 44 [300/414 (72%)]\tLosses 0.4385\n",
      "Train Epoch: 44 [400/414 (97%)]\tLosses 0.7134\n",
      "Train Epoch: 45 [0/414 (0%)]\tLosses 0.6735\n",
      "Train Epoch: 45 [100/414 (24%)]\tLosses 0.5266\n",
      "Train Epoch: 45 [200/414 (48%)]\tLosses 0.5564\n",
      "Train Epoch: 45 [300/414 (72%)]\tLosses 1.2498\n",
      "Train Epoch: 45 [400/414 (97%)]\tLosses 0.8154\n",
      "Train Epoch: 46 [0/414 (0%)]\tLosses 0.6947\n",
      "Train Epoch: 46 [100/414 (24%)]\tLosses 0.4901\n",
      "Train Epoch: 46 [200/414 (48%)]\tLosses 0.7513\n",
      "Train Epoch: 46 [300/414 (72%)]\tLosses 0.6383\n",
      "Train Epoch: 46 [400/414 (97%)]\tLosses 5.4418\n",
      "Train Epoch: 47 [0/414 (0%)]\tLosses 0.5773\n",
      "Train Epoch: 47 [100/414 (24%)]\tLosses 0.9035\n",
      "Train Epoch: 47 [200/414 (48%)]\tLosses 0.6720\n",
      "Train Epoch: 47 [300/414 (72%)]\tLosses 0.8837\n",
      "Train Epoch: 47 [400/414 (97%)]\tLosses 0.7253\n",
      "Train Epoch: 48 [0/414 (0%)]\tLosses 0.9283\n",
      "Train Epoch: 48 [100/414 (24%)]\tLosses 2.1528\n",
      "Train Epoch: 48 [200/414 (48%)]\tLosses 0.6618\n",
      "Train Epoch: 48 [300/414 (72%)]\tLosses 0.6016\n",
      "Train Epoch: 48 [400/414 (97%)]\tLosses 0.6826\n",
      "Train Epoch: 49 [0/414 (0%)]\tLosses 0.5248\n",
      "Train Epoch: 49 [100/414 (24%)]\tLosses 0.5731\n",
      "Train Epoch: 49 [200/414 (48%)]\tLosses 0.5792\n",
      "Train Epoch: 49 [300/414 (72%)]\tLosses 1.2028\n",
      "Train Epoch: 49 [400/414 (97%)]\tLosses 0.7290\n",
      "Train Epoch: 50 [0/414 (0%)]\tLosses 1.3698\n",
      "Train Epoch: 50 [100/414 (24%)]\tLosses 1.3754\n",
      "Train Epoch: 50 [200/414 (48%)]\tLosses 0.7120\n",
      "Train Epoch: 50 [300/414 (72%)]\tLosses 0.7482\n",
      "Train Epoch: 50 [400/414 (97%)]\tLosses 0.7076\n",
      "Train Epoch: 51 [0/414 (0%)]\tLosses 0.6175\n",
      "Train Epoch: 51 [100/414 (24%)]\tLosses 1.0502\n",
      "Train Epoch: 51 [200/414 (48%)]\tLosses 1.4240\n",
      "Train Epoch: 51 [300/414 (72%)]\tLosses 1.0861\n",
      "Train Epoch: 51 [400/414 (97%)]\tLosses 0.9912\n",
      "Train Epoch: 52 [0/414 (0%)]\tLosses 1.0245\n",
      "Train Epoch: 52 [100/414 (24%)]\tLosses 0.4608\n",
      "Train Epoch: 52 [200/414 (48%)]\tLosses 6.8017\n",
      "Train Epoch: 52 [300/414 (72%)]\tLosses 0.6382\n",
      "Train Epoch: 52 [400/414 (97%)]\tLosses 0.6141\n",
      "Train Epoch: 53 [0/414 (0%)]\tLosses 0.8579\n",
      "Train Epoch: 53 [100/414 (24%)]\tLosses 0.6224\n",
      "Train Epoch: 53 [200/414 (48%)]\tLosses 0.6166\n",
      "Train Epoch: 53 [300/414 (72%)]\tLosses 0.7238\n",
      "Train Epoch: 53 [400/414 (97%)]\tLosses 0.5960\n",
      "Train Epoch: 54 [0/414 (0%)]\tLosses 0.7668\n",
      "Train Epoch: 54 [100/414 (24%)]\tLosses 0.7018\n",
      "Train Epoch: 54 [200/414 (48%)]\tLosses 0.4523\n",
      "Train Epoch: 54 [300/414 (72%)]\tLosses 0.8653\n",
      "Train Epoch: 54 [400/414 (97%)]\tLosses 1.1786\n",
      "Train Epoch: 55 [0/414 (0%)]\tLosses 0.7894\n",
      "Train Epoch: 55 [100/414 (24%)]\tLosses 3.9300\n",
      "Train Epoch: 55 [200/414 (48%)]\tLosses 0.7034\n",
      "Train Epoch: 55 [300/414 (72%)]\tLosses 2.5486\n",
      "Train Epoch: 55 [400/414 (97%)]\tLosses 0.5685\n",
      "Train Epoch: 56 [0/414 (0%)]\tLosses 2.2399\n",
      "Train Epoch: 56 [100/414 (24%)]\tLosses 0.5996\n",
      "Train Epoch: 56 [200/414 (48%)]\tLosses 0.4836\n",
      "Train Epoch: 56 [300/414 (72%)]\tLosses 0.6340\n",
      "Train Epoch: 56 [400/414 (97%)]\tLosses 0.5736\n",
      "Train Epoch: 57 [0/414 (0%)]\tLosses 9.1400\n",
      "Train Epoch: 57 [100/414 (24%)]\tLosses 0.4465\n",
      "Train Epoch: 57 [200/414 (48%)]\tLosses 0.7506\n",
      "Train Epoch: 57 [300/414 (72%)]\tLosses 4.2846\n",
      "Train Epoch: 57 [400/414 (97%)]\tLosses 0.6330\n",
      "Train Epoch: 58 [0/414 (0%)]\tLosses 0.4883\n",
      "Train Epoch: 58 [100/414 (24%)]\tLosses 0.7103\n",
      "Train Epoch: 58 [200/414 (48%)]\tLosses 0.9488\n",
      "Train Epoch: 58 [300/414 (72%)]\tLosses 0.8332\n",
      "Train Epoch: 58 [400/414 (97%)]\tLosses 0.7249\n",
      "Train Epoch: 59 [0/414 (0%)]\tLosses 0.8426\n",
      "Train Epoch: 59 [100/414 (24%)]\tLosses 0.4784\n",
      "Train Epoch: 59 [200/414 (48%)]\tLosses 1.1197\n",
      "Train Epoch: 59 [300/414 (72%)]\tLosses 0.9178\n",
      "Train Epoch: 59 [400/414 (97%)]\tLosses 0.8205\n",
      "Train Epoch: 60 [0/414 (0%)]\tLosses 1.7807\n",
      "Train Epoch: 60 [100/414 (24%)]\tLosses 0.7763\n",
      "Train Epoch: 60 [200/414 (48%)]\tLosses 7.3376\n",
      "Train Epoch: 60 [300/414 (72%)]\tLosses 0.5465\n",
      "Train Epoch: 60 [400/414 (97%)]\tLosses 0.6482\n",
      "Train Epoch: 61 [0/414 (0%)]\tLosses 0.8609\n",
      "Train Epoch: 61 [100/414 (24%)]\tLosses 0.8281\n",
      "Train Epoch: 61 [200/414 (48%)]\tLosses 0.9471\n",
      "Train Epoch: 61 [300/414 (72%)]\tLosses 0.4128\n",
      "Train Epoch: 61 [400/414 (97%)]\tLosses 0.6131\n",
      "Train Epoch: 62 [0/414 (0%)]\tLosses 1.3579\n",
      "Train Epoch: 62 [100/414 (24%)]\tLosses 0.7286\n",
      "Train Epoch: 62 [200/414 (48%)]\tLosses 0.4355\n",
      "Train Epoch: 62 [300/414 (72%)]\tLosses 1.3944\n",
      "Train Epoch: 62 [400/414 (97%)]\tLosses 0.5626\n",
      "Train Epoch: 63 [0/414 (0%)]\tLosses 0.6911\n",
      "Train Epoch: 63 [100/414 (24%)]\tLosses 0.5538\n",
      "Train Epoch: 63 [200/414 (48%)]\tLosses 0.7636\n",
      "Train Epoch: 63 [300/414 (72%)]\tLosses 0.5772\n",
      "Train Epoch: 63 [400/414 (97%)]\tLosses 0.6837\n",
      "Train Epoch: 64 [0/414 (0%)]\tLosses 0.7265\n",
      "Train Epoch: 64 [100/414 (24%)]\tLosses 0.5247\n",
      "Train Epoch: 64 [200/414 (48%)]\tLosses 1.6208\n",
      "Train Epoch: 64 [300/414 (72%)]\tLosses 0.5985\n",
      "Train Epoch: 64 [400/414 (97%)]\tLosses 1.7076\n",
      "Train Epoch: 65 [0/414 (0%)]\tLosses 1.5857\n",
      "Train Epoch: 65 [100/414 (24%)]\tLosses 0.5377\n",
      "Train Epoch: 65 [200/414 (48%)]\tLosses 0.7731\n",
      "Train Epoch: 65 [300/414 (72%)]\tLosses 1.1748\n",
      "Train Epoch: 65 [400/414 (97%)]\tLosses 0.8127\n",
      "Train Epoch: 66 [0/414 (0%)]\tLosses 1.0885\n",
      "Train Epoch: 66 [100/414 (24%)]\tLosses 0.6747\n",
      "Train Epoch: 66 [200/414 (48%)]\tLosses 1.4188\n",
      "Train Epoch: 66 [300/414 (72%)]\tLosses 0.6408\n",
      "Train Epoch: 66 [400/414 (97%)]\tLosses 0.6421\n",
      "Train Epoch: 67 [0/414 (0%)]\tLosses 5.6005\n",
      "Train Epoch: 67 [100/414 (24%)]\tLosses 9.3338\n",
      "Train Epoch: 67 [200/414 (48%)]\tLosses 1.4008\n",
      "Train Epoch: 67 [300/414 (72%)]\tLosses 0.5450\n",
      "Train Epoch: 67 [400/414 (97%)]\tLosses 0.7292\n",
      "Train Epoch: 68 [0/414 (0%)]\tLosses 1.8813\n",
      "Train Epoch: 68 [100/414 (24%)]\tLosses 1.0617\n",
      "Train Epoch: 68 [200/414 (48%)]\tLosses 0.9183\n",
      "Train Epoch: 68 [300/414 (72%)]\tLosses 0.5643\n",
      "Train Epoch: 68 [400/414 (97%)]\tLosses 0.4542\n",
      "Train Epoch: 69 [0/414 (0%)]\tLosses 0.6011\n",
      "Train Epoch: 69 [100/414 (24%)]\tLosses 0.7500\n",
      "Train Epoch: 69 [200/414 (48%)]\tLosses 0.6022\n",
      "Train Epoch: 69 [300/414 (72%)]\tLosses 1.1755\n",
      "Train Epoch: 69 [400/414 (97%)]\tLosses 0.8941\n",
      "Train Epoch: 70 [0/414 (0%)]\tLosses 0.5533\n",
      "Train Epoch: 70 [100/414 (24%)]\tLosses 1.0072\n",
      "Train Epoch: 70 [200/414 (48%)]\tLosses 1.3807\n",
      "Train Epoch: 70 [300/414 (72%)]\tLosses 0.4574\n",
      "Train Epoch: 70 [400/414 (97%)]\tLosses 0.4181\n",
      "Train Epoch: 71 [0/414 (0%)]\tLosses 0.5919\n",
      "Train Epoch: 71 [100/414 (24%)]\tLosses 0.7298\n",
      "Train Epoch: 71 [200/414 (48%)]\tLosses 0.9046\n",
      "Train Epoch: 71 [300/414 (72%)]\tLosses 0.6626\n",
      "Train Epoch: 71 [400/414 (97%)]\tLosses 0.5030\n",
      "Train Epoch: 72 [0/414 (0%)]\tLosses 0.5339\n",
      "Train Epoch: 72 [100/414 (24%)]\tLosses 0.6558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 72 [200/414 (48%)]\tLosses 0.9081\n",
      "Train Epoch: 72 [300/414 (72%)]\tLosses 1.1675\n",
      "Train Epoch: 72 [400/414 (97%)]\tLosses 3.5415\n",
      "Train Epoch: 73 [0/414 (0%)]\tLosses 0.7004\n",
      "Train Epoch: 73 [100/414 (24%)]\tLosses 0.5830\n",
      "Train Epoch: 73 [200/414 (48%)]\tLosses 0.5345\n",
      "Train Epoch: 73 [300/414 (72%)]\tLosses 0.4886\n",
      "Train Epoch: 73 [400/414 (97%)]\tLosses 0.4608\n",
      "Train Epoch: 74 [0/414 (0%)]\tLosses 0.7954\n",
      "Train Epoch: 74 [100/414 (24%)]\tLosses 0.8085\n",
      "Train Epoch: 74 [200/414 (48%)]\tLosses 0.5170\n",
      "Train Epoch: 74 [300/414 (72%)]\tLosses 0.4479\n",
      "Train Epoch: 74 [400/414 (97%)]\tLosses 0.7706\n",
      "Train Epoch: 75 [0/414 (0%)]\tLosses 0.6464\n",
      "Train Epoch: 75 [100/414 (24%)]\tLosses 0.4496\n",
      "Train Epoch: 75 [200/414 (48%)]\tLosses 1.2528\n",
      "Train Epoch: 75 [300/414 (72%)]\tLosses 2.5849\n",
      "Train Epoch: 75 [400/414 (97%)]\tLosses 0.8965\n",
      "Train Epoch: 76 [0/414 (0%)]\tLosses 0.7136\n",
      "Train Epoch: 76 [100/414 (24%)]\tLosses 0.9715\n",
      "Train Epoch: 76 [200/414 (48%)]\tLosses 0.5225\n",
      "Train Epoch: 76 [300/414 (72%)]\tLosses 0.5230\n",
      "Train Epoch: 76 [400/414 (97%)]\tLosses 0.6220\n",
      "Train Epoch: 77 [0/414 (0%)]\tLosses 0.8352\n",
      "Train Epoch: 77 [100/414 (24%)]\tLosses 0.5901\n",
      "Train Epoch: 77 [200/414 (48%)]\tLosses 0.4358\n",
      "Train Epoch: 77 [300/414 (72%)]\tLosses 0.5501\n",
      "Train Epoch: 77 [400/414 (97%)]\tLosses 0.8951\n",
      "Train Epoch: 78 [0/414 (0%)]\tLosses 0.9777\n",
      "Train Epoch: 78 [100/414 (24%)]\tLosses 0.4195\n",
      "Train Epoch: 78 [200/414 (48%)]\tLosses 0.5275\n",
      "Train Epoch: 78 [300/414 (72%)]\tLosses 1.2107\n",
      "Train Epoch: 78 [400/414 (97%)]\tLosses 0.6645\n",
      "Train Epoch: 79 [0/414 (0%)]\tLosses 1.0920\n",
      "Train Epoch: 79 [100/414 (24%)]\tLosses 4.4824\n",
      "Train Epoch: 79 [200/414 (48%)]\tLosses 1.2853\n",
      "Train Epoch: 79 [300/414 (72%)]\tLosses 0.4830\n",
      "Train Epoch: 79 [400/414 (97%)]\tLosses 0.5819\n",
      "Train Epoch: 80 [0/414 (0%)]\tLosses 0.8451\n",
      "Train Epoch: 80 [100/414 (24%)]\tLosses 0.8654\n",
      "Train Epoch: 80 [200/414 (48%)]\tLosses 0.7593\n",
      "Train Epoch: 80 [300/414 (72%)]\tLosses 0.6089\n",
      "Train Epoch: 80 [400/414 (97%)]\tLosses 1.2359\n",
      "Train Epoch: 81 [0/414 (0%)]\tLosses 0.8327\n",
      "Train Epoch: 81 [100/414 (24%)]\tLosses 1.3698\n",
      "Train Epoch: 81 [200/414 (48%)]\tLosses 0.7647\n",
      "Train Epoch: 81 [300/414 (72%)]\tLosses 0.4913\n",
      "Train Epoch: 81 [400/414 (97%)]\tLosses 0.4753\n",
      "Train Epoch: 82 [0/414 (0%)]\tLosses 0.9892\n",
      "Train Epoch: 82 [100/414 (24%)]\tLosses 0.8765\n",
      "Train Epoch: 82 [200/414 (48%)]\tLosses 0.6499\n",
      "Train Epoch: 82 [300/414 (72%)]\tLosses 0.5332\n",
      "Train Epoch: 82 [400/414 (97%)]\tLosses 0.5924\n",
      "Train Epoch: 83 [0/414 (0%)]\tLosses 0.5153\n",
      "Train Epoch: 83 [100/414 (24%)]\tLosses 0.9125\n",
      "Train Epoch: 83 [200/414 (48%)]\tLosses 0.7016\n",
      "Train Epoch: 83 [300/414 (72%)]\tLosses 0.5502\n",
      "Train Epoch: 83 [400/414 (97%)]\tLosses 1.0733\n",
      "Train Epoch: 84 [0/414 (0%)]\tLosses 0.6449\n",
      "Train Epoch: 84 [100/414 (24%)]\tLosses 0.4659\n",
      "Train Epoch: 84 [200/414 (48%)]\tLosses 0.7112\n",
      "Train Epoch: 84 [300/414 (72%)]\tLosses 0.5382\n",
      "Train Epoch: 84 [400/414 (97%)]\tLosses 0.5589\n",
      "Train Epoch: 85 [0/414 (0%)]\tLosses 0.8533\n",
      "Train Epoch: 85 [100/414 (24%)]\tLosses 1.8007\n",
      "Train Epoch: 85 [200/414 (48%)]\tLosses 1.4861\n",
      "Train Epoch: 85 [300/414 (72%)]\tLosses 3.0513\n",
      "Train Epoch: 85 [400/414 (97%)]\tLosses 1.1240\n",
      "Train Epoch: 86 [0/414 (0%)]\tLosses 0.8309\n",
      "Train Epoch: 86 [100/414 (24%)]\tLosses 0.8973\n",
      "Train Epoch: 86 [200/414 (48%)]\tLosses 1.0124\n",
      "Train Epoch: 86 [300/414 (72%)]\tLosses 0.5945\n",
      "Train Epoch: 86 [400/414 (97%)]\tLosses 0.7536\n",
      "Train Epoch: 87 [0/414 (0%)]\tLosses 0.8035\n",
      "Train Epoch: 87 [100/414 (24%)]\tLosses 1.6365\n",
      "Train Epoch: 87 [200/414 (48%)]\tLosses 0.7573\n",
      "Train Epoch: 87 [300/414 (72%)]\tLosses 0.4797\n",
      "Train Epoch: 87 [400/414 (97%)]\tLosses 1.0029\n",
      "Train Epoch: 88 [0/414 (0%)]\tLosses 0.7435\n",
      "Train Epoch: 88 [100/414 (24%)]\tLosses 0.5821\n",
      "Train Epoch: 88 [200/414 (48%)]\tLosses 1.2601\n",
      "Train Epoch: 88 [300/414 (72%)]\tLosses 0.8469\n",
      "Train Epoch: 88 [400/414 (97%)]\tLosses 0.6457\n",
      "Train Epoch: 89 [0/414 (0%)]\tLosses 0.6662\n",
      "Train Epoch: 89 [100/414 (24%)]\tLosses 0.8266\n",
      "Train Epoch: 89 [200/414 (48%)]\tLosses 0.7205\n",
      "Train Epoch: 89 [300/414 (72%)]\tLosses 0.9142\n",
      "Train Epoch: 89 [400/414 (97%)]\tLosses 0.6796\n",
      "Train Epoch: 90 [0/414 (0%)]\tLosses 0.7766\n",
      "Train Epoch: 90 [100/414 (24%)]\tLosses 1.3670\n",
      "Train Epoch: 90 [200/414 (48%)]\tLosses 1.0580\n",
      "Train Epoch: 90 [300/414 (72%)]\tLosses 1.1428\n",
      "Train Epoch: 90 [400/414 (97%)]\tLosses 1.2484\n",
      "Train Epoch: 91 [0/414 (0%)]\tLosses 0.6992\n",
      "Train Epoch: 91 [100/414 (24%)]\tLosses 0.7509\n",
      "Train Epoch: 91 [200/414 (48%)]\tLosses 6.3922\n",
      "Train Epoch: 91 [300/414 (72%)]\tLosses 0.5521\n",
      "Train Epoch: 91 [400/414 (97%)]\tLosses 4.5292\n",
      "Train Epoch: 92 [0/414 (0%)]\tLosses 1.8080\n",
      "Train Epoch: 92 [100/414 (24%)]\tLosses 1.1212\n",
      "Train Epoch: 92 [200/414 (48%)]\tLosses 0.8363\n",
      "Train Epoch: 92 [300/414 (72%)]\tLosses 1.3738\n",
      "Train Epoch: 92 [400/414 (97%)]\tLosses 0.6200\n",
      "Train Epoch: 93 [0/414 (0%)]\tLosses 0.7776\n",
      "Train Epoch: 93 [100/414 (24%)]\tLosses 0.4950\n",
      "Train Epoch: 93 [200/414 (48%)]\tLosses 0.6193\n",
      "Train Epoch: 93 [300/414 (72%)]\tLosses 0.4530\n",
      "Train Epoch: 93 [400/414 (97%)]\tLosses 0.5604\n",
      "Train Epoch: 94 [0/414 (0%)]\tLosses 0.4573\n",
      "Train Epoch: 94 [100/414 (24%)]\tLosses 0.7536\n",
      "Train Epoch: 94 [200/414 (48%)]\tLosses 1.6379\n",
      "Train Epoch: 94 [300/414 (72%)]\tLosses 0.7394\n",
      "Train Epoch: 94 [400/414 (97%)]\tLosses 0.4778\n",
      "Train Epoch: 95 [0/414 (0%)]\tLosses 0.9014\n",
      "Train Epoch: 95 [100/414 (24%)]\tLosses 0.5221\n",
      "Train Epoch: 95 [200/414 (48%)]\tLosses 1.8526\n",
      "Train Epoch: 95 [300/414 (72%)]\tLosses 1.0095\n",
      "Train Epoch: 95 [400/414 (97%)]\tLosses 1.8487\n",
      "Train Epoch: 96 [0/414 (0%)]\tLosses 6.0212\n",
      "Train Epoch: 96 [100/414 (24%)]\tLosses 0.9652\n",
      "Train Epoch: 96 [200/414 (48%)]\tLosses 0.7850\n",
      "Train Epoch: 96 [300/414 (72%)]\tLosses 0.3733\n",
      "Train Epoch: 96 [400/414 (97%)]\tLosses 1.0319\n",
      "Train Epoch: 97 [0/414 (0%)]\tLosses 1.1614\n",
      "Train Epoch: 97 [100/414 (24%)]\tLosses 0.7266\n",
      "Train Epoch: 97 [200/414 (48%)]\tLosses 0.4619\n",
      "Train Epoch: 97 [300/414 (72%)]\tLosses 0.7698\n",
      "Train Epoch: 97 [400/414 (97%)]\tLosses 0.8117\n",
      "Train Epoch: 98 [0/414 (0%)]\tLosses 0.8727\n",
      "Train Epoch: 98 [100/414 (24%)]\tLosses 0.7716\n",
      "Train Epoch: 98 [200/414 (48%)]\tLosses 0.7325\n",
      "Train Epoch: 98 [300/414 (72%)]\tLosses 0.6128\n",
      "Train Epoch: 98 [400/414 (97%)]\tLosses 0.6511\n",
      "Train Epoch: 99 [0/414 (0%)]\tLosses 0.7326\n",
      "Train Epoch: 99 [100/414 (24%)]\tLosses 0.8109\n",
      "Train Epoch: 99 [200/414 (48%)]\tLosses 0.9531\n",
      "Train Epoch: 99 [300/414 (72%)]\tLosses 0.6067\n",
      "Train Epoch: 99 [400/414 (97%)]\tLosses 0.5681\n",
      "Test loss=0.5518\n",
      "y_pred= tensor([ 1.6736,  0.0000,  0.9384,  1.0823,  1.1617,  0.7184,  2.3995,  0.9180,\n",
      "         0.0000,  0.0000,  0.6988,  0.8356,  1.7250,  0.8809,  0.6410,  1.4734,\n",
      "         0.0000,  1.3349,  0.5359,  1.4054,  1.3241,  0.8545,  2.0472,  2.1931,\n",
      "         0.0000,  8.6756,  0.5162,  0.8216,  1.4372,  2.4110,  0.6119,  1.1590,\n",
      "         1.5473,  0.5281,  1.7437,  1.3410,  1.9868,  0.7692,  0.8321,  0.0000,\n",
      "         0.0000,  1.5043,  1.3643,  0.9941,  1.5930,  0.9710,  0.0000,  2.6627,\n",
      "         2.5487,  2.0867,  0.7366,  0.5867,  0.9377,  0.9789,  1.5152,  0.0000,\n",
      "         0.0000,  0.0000,  0.6461,  0.0000,  3.9239,  1.1339,  0.8524,  0.6670,\n",
      "         0.0000,  2.1460,  0.7634,  0.0000,  0.6545,  2.0584,  0.0000,  0.4425,\n",
      "         0.9846,  9.8948,  0.7093,  0.0000,  0.0000,  1.2879,  0.7368,  1.7065,\n",
      "         1.6174,  0.7696,  0.0000,  0.9527,  0.6740,  1.1236,  0.0000,  1.0776,\n",
      "         0.8342,  1.5841,  0.4576,  0.8133,  0.8017,  1.2521,  0.5622,  2.9337,\n",
      "         1.1610,  0.5432,  0.4675,  3.3162,  2.2645,  0.0000,  4.2266,  0.1788,\n",
      "         1.3634,  0.0000,  1.2242,  1.8584,  1.2769,  1.4382,  1.8244,  1.3252,\n",
      "         1.4971,  1.6607,  2.1833,  0.0000, 13.8586,  0.9519,  0.4271,  0.0000,\n",
      "         0.5298,  0.8148,  0.2820,  1.8357,  2.0000,  1.0115,  2.1367,  1.1431,\n",
      "         0.8569,  0.6060,  0.7495,  0.0000,  0.0918,  1.2786,  1.2638,  1.1637,\n",
      "         0.7726,  1.3702,  0.0000,  0.5736,  0.4814,  0.5693,  3.9139,  0.0000,\n",
      "         0.6470,  0.6620,  0.1229,  2.9731,  0.5305,  0.0000,  1.7836,  1.0935,\n",
      "         1.9642,  0.9031,  1.9407,  2.3080,  0.5327,  1.3364,  0.8864,  3.6251,\n",
      "         1.2411,  1.4774,  3.4821,  1.2206,  0.9566,  0.7635,  2.1328,  4.7961,\n",
      "         1.7849,  1.7042,  0.8466,  1.0942,  0.0000,  0.6056,  0.7297,  0.6971,\n",
      "         0.8974,  0.0000,  1.5589,  1.8596,  0.0000,  0.0000,  1.0055,  0.5479,\n",
      "         0.0000,  0.3249,  3.4785,  1.7044,  2.8182,  1.1255,  0.9738,  0.0000,\n",
      "         0.8269,  7.6972,  1.2036,  4.1880,  5.0390,  4.3419,  1.5042,  2.8296],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "y_test= tensor([ 0.9190,  0.4150,  0.3500,  0.4560,  1.0800,  1.4380,  2.0790,  0.4700,\n",
      "         0.1940,  1.7310,  0.1310,  0.4200,  0.8710,  0.8800,  0.9920,  1.7880,\n",
      "         1.1220,  1.4740,  0.1520,  1.4350,  0.5760,  0.3870,  1.0410,  1.0600,\n",
      "         0.2170,  7.4190,  0.3880,  0.8830,  0.5520,  2.5760,  0.4900,  0.6750,\n",
      "         2.7360,  0.2200,  1.7400,  0.6540,  1.8910,  0.4730,  0.1970,  0.9100,\n",
      "         0.1770,  1.3880,  1.5490,  0.8600,  1.3940,  1.0790,  0.5840,  2.3010,\n",
      "         1.4120,  1.4400,  0.8260,  0.3320,  1.7180,  1.0960,  0.9300,  0.4570,\n",
      "         0.1690,  0.2670,  0.5800,  0.2080,  4.0600,  1.4400,  1.2100,  0.4300,\n",
      "         0.2930,  1.5960,  0.5040,  0.0570,  1.9530,  0.7850,  0.7280,  0.5430,\n",
      "         1.0790,  9.0440,  0.5850,  0.2670,  0.3200,  1.7930,  1.2910,  1.6300,\n",
      "         1.6290,  0.2470,  0.2330,  1.1530,  0.7580,  0.9750,  0.1730,  0.6590,\n",
      "         0.9370,  1.0930,  0.4610,  0.5000,  1.1940,  1.7560,  0.4520,  2.8700,\n",
      "         0.2940,  0.2550,  0.4970,  4.4900,  1.6100,  0.8980,  2.1700,  0.5040,\n",
      "         0.6290,  0.1080,  0.9400,  0.8600,  1.0990,  1.1830,  1.5880,  0.8500,\n",
      "         0.8180,  1.4780,  1.7880,  0.0810, 10.2700,  1.1050,  0.3750,  0.4620,\n",
      "         0.3650,  0.9720,  0.3800,  2.3280,  1.2390,  1.3380,  2.6530,  1.0680,\n",
      "         1.6000,  0.1890,  0.2870,  0.4300,  0.3830,  0.6460,  1.3340,  0.9070,\n",
      "         0.2900,  0.6300,  0.6060,  0.2100,  0.4770,  0.2860,  4.6400,  0.4660,\n",
      "         0.6700,  0.3700,  0.1620,  1.7580,  0.5270,  1.8340,  1.0080,  0.8600,\n",
      "         2.4360,  0.3510,  1.3100,  2.5750,  0.8130,  4.4990,  0.3820,  2.1150,\n",
      "         1.6600,  0.1800,  5.9980,  1.8720,  0.8110,  0.5200,  0.7900,  2.9840,\n",
      "         1.3730,  1.4160,  0.2500,  1.0800,  0.3130,  0.9300,  0.4300,  2.2330,\n",
      "         0.3700,  0.7480,  1.6830,  1.5860,  0.2890,  0.4620,  0.7200,  1.4670,\n",
      "         0.2820,  0.2740,  3.2790,  1.1010,  3.2640,  0.8640,  1.0130,  0.6380,\n",
      "         0.2580,  7.3680,  0.9240,  2.8640,  8.0800,  3.9060,  1.5060,  1.4140],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader)\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    output = model.forward(test_cats,test_conts).cuda()\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
